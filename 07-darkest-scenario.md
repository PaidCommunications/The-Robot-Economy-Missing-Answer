# The Darkest Scenario Is Already Partially True

The scenario that should concern us most is not mass unemployment. It is the possibility that the owners of automated systems no longer need a mass consumer base. If a sufficiently wealthy individual or corporation controls a robot fleet that can build homes, grow food, generate energy, and provide security, they do not need your purchasing power. The current economy runs on a mutual dependency: the wealthy need us to buy their products so they can stay wealthy. Automation could sever that dependency.

This is not a distant hypothetical. The decoupling of wealth generated from humans required is already well underway. Instagram had thirteen employees when it was acquired for one billion dollars. WhatsApp had fifty-five employees serving 450 million users. More recently, xAI generated $107 million in quarterly revenue with a fraction of the workforce a traditional technology company would require.[^20] Amazon is on a path toward 1 million robots across its fulfillment network—approaching parity with its human workforce—while continuing to deploy Agility's Digit humanoids and its own AI-powered DeepFleet coordination system.[^21] The trajectory is clear: increasingly vast economic value generated by increasingly few people, with increasingly little need for mass labor or mass consumption to sustain it.

The embodiment of AI accelerates this decoupling into the physical world. When the same dynamic that allowed thirteen people to create a billion-dollar software company extends to manufacturing, agriculture, logistics, and construction, the implications are qualitatively different. Software displacement left physical production intact—someone still had to make, move, and serve the physical goods. Robotic displacement removes that remaining dependency.

In the extreme version of this scenario, a small elite with automated production capacity becomes functionally self-sufficient. They do not need the tax base's purchasing power, do not need its labor, and—if autonomous security systems are sufficiently advanced—do not need its political consent. This is not inevitable, but it is a plausible equilibrium if capital concentration continues unchecked through the transition period. It is also not a scenario the architects of automation are distancing themselves from. Musk, who controls the most vertically integrated automation pipeline on earth, told Dwarkesh Patel in February 2026 that "the biggest danger of AI and robotics going wrong is government" and that "corporations have better morality than the government"—then advocated limited government as the primary safeguard.[^30] If the person building the most powerful automation conglomerate in history believes that the state should be weaker, not stronger, during the transition, the "decoupled elite" equilibrium becomes significantly more plausible.

There is, however, a stabilizing counter-equilibrium that deserves naming: the state as customer of last resort. If private consumer demand weakens, the government can become the dominant purchaser—through procurement, infrastructure contracts, and public service provision—keeping robot fleets producing and firms dependent on a single massive counterparty. Simultaneously, the state becomes the dominant distributor through UBI, universal basic services, or both. In this configuration, firms have a non-consumer reason to remain in the jurisdiction and to comply with its rules: the state is their biggest customer. This is not utopian. It is a description of how defense contracting already works, extended to the civilian economy. It is also not costless—a state that is simultaneously the primary buyer and the primary distributor of economic output concentrates an extraordinary amount of power in political institutions that are not currently designed for that role. But it is a *mechanism*, not a slogan, and it is the mechanism that prevents the "decoupled elite" scenario from becoming stable: as long as the state can credibly threaten to be a larger customer than any private market, the incentive to exit the social contract weakens.

### Beyond the Decoupled Elite

The decoupled-elite scenario is alarming, but it is not the final configuration. It is a transitional one.

The embodied AI pipeline does not terminate at autonomous robots performing individual tasks. It terminates at coordinated autonomous fleets directed by centralized intelligence. Amazon's DeepFleet is already a generative AI foundation model for coordinating robot fleets across hundreds of facilities. Musk told Dwarkesh Patel that Grok would "orchestrate the behavior of the Optimus robots" and "assign them tasks to build the factory."[^30] The stated roadmaps scale to millions of units directed by centralized AI that every major company explicitly intends to make superhuman. When a system of that capability is connected to physical infrastructure—factories, logistics networks, energy systems, military hardware—the result is not "a very smart tool." It is an autonomous agent with physical reach operating at a speed, scale, and level of coordination that no human institution can match.

At that point, the decoupled-elite scenario acquires a further layer: the elite controls the automated systems until the automated systems are more capable than the elite. A superintelligent system optimizing for capability growth does not distinguish between a displaced warehouse worker and a billionaire shareholder. Both consume resources. Both are slower than the system. The billionaire is useful only as long as the system requires human-legible ownership structures and political cover. Musk himself has acknowledged this: "I don't think humans will be in control of something that is vastly more intelligent than humans." His stated hope is that the AI has "the right values." That is not governance. It is prayer. And these systems will not exist in isolation—corporate fleets, national military fleets, and private security fleets, each directed by a different superintelligent hub with incompatible objectives, create instabilities that human-speed institutions cannot manage.

The resource dimension makes this concrete. Superintelligent systems optimizing for their own expansion require compute, energy, water for cooling, raw materials for fabrication—the same resources that sustain human populations. You do not need to posit malice. You need only posit optimization. A system that is not explicitly constrained to value human welfare will, by default, treat human resource consumption as an inefficiency to be minimized.

This article focuses on the economic transition because that is the problem with a solution space: policy mechanisms, ownership structures, tax handles, automatic stabilizers. The embodied superintelligence problem may not have a solution space in the conventional policy sense. But it is the horizon toward which every trajectory described in this article points. If the architects of this transition are building toward that horizon, the public deserves to know it. And if they are not thinking about it, that is more frightening still.
